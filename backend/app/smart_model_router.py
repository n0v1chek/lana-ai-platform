"""
–£–º–Ω—ã–π —Ä–æ—É—Ç–µ—Ä –º–æ–¥–µ–ª–µ–π - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
–Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞—á–∏, —Ç–∞—Ä–∏—Ñ–∞ –∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ª–∏–º–∏—Ç–æ–≤
"""

import re
from typing import List, Dict, Optional
from subscription_plans_optimized import (
    SubscriptionTier,
    ModelCategory,
    get_model_category,
    get_model_cost,
    get_recommended_model,
    MODEL_ACCESS_RULES,
)

class SmartModelRouter:
    """–£–º–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ —Ç–∞—Ä–∏—Ñ–∞"""
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
    TASK_KEYWORDS = {
        "coding": [
            "–∫–æ–¥", "code", "python", "javascript", "–ø—Ä–æ–≥—Ä–∞–º–º", "—Ñ—É–Ω–∫—Ü–∏",
            "class", "def", "import", "script", "debug", "–æ—à–∏–±–∫–∞", "bug",
            "api", "sql", "html", "css", "react", "django", "flask"
        ],
        "creative": [
            "–Ω–∞–ø–∏—à–∏", "write", "story", "—Å—Ç–∞—Ç—å—è", "article", "—Ç–µ–∫—Å—Ç",
            "—Å–æ—á–∏–Ω–µ–Ω–∏–µ", "essay", "–ø–æ—ç–º", "poem", "—Å—Ç–∏—Ö", "—Ç–≤–æ—Ä—á–µ—Å—Ç–≤",
            "–∫—Ä–µ–∞—Ç–∏–≤", "creative", "–ø—Ä–∏–¥—É–º–∞–π", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–µ–∫—Å—Ç"
        ],
        "analysis": [
            "–∞–Ω–∞–ª–∏–∑", "analysis", "—Å—Ä–∞–≤–Ω–∏", "compare", "–æ—Ü–µ–Ω–∏", "evaluate",
            "–∏—Å—Å–ª–µ–¥—É–π", "research", "–∏–∑—É—á–∏", "study", "—Ä–∞–∑–±–æ—Ä", "–æ–±—ä—è—Å–Ω–∏",
            "–ø–æ—á–µ–º—É", "why", "–ø—Ä–∏—á–∏–Ω–∞", "reason", "–≤—ã–≤–æ–¥", "conclusion"
        ],
        "translation": [
            "–ø–µ—Ä–µ–≤–æ–¥", "translate", "translation", "–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π", "–Ω–∞ —Ä—É—Å—Å–∫–∏–π",
            "to english", "to russian", "—è–∑—ã–∫–∞"
        ],
        "math": [
            "–ø–æ—Å—á–∏—Ç–∞–π", "calculate", "–º–∞—Ç–µ–º–∞—Ç–∏–∫", "math", "—Ñ–æ—Ä–º—É–ª–∞", "formula",
            "—É—Ä–∞–≤–Ω–µ–Ω–∏–µ", "equation", "–∑–∞–¥–∞—á–∞", "problem", "—Ä–µ—à–µ–Ω–∏–µ", "solution"
        ],
    }
    
    def __init__(self):
        pass
    
    def detect_task_type(self, message: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∑–∞–¥–∞—á–∏ –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Returns:
            "coding" | "creative" | "analysis" | "translation" | "math" | "general"
        """
        message_lower = message.lower()
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
        scores = {}
        for task_type, keywords in self.TASK_KEYWORDS.items():
            score = sum(1 for keyword in keywords if keyword in message_lower)
            if score > 0:
                scores[task_type] = score
        
        if not scores:
            return "general"
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∏–ø —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        return max(scores.items(), key=lambda x: x[1])[0]
    
    def estimate_tokens(self, message: str, conversation_history: List[Dict] = None) -> int:
        """
        –û—Ü–µ–Ω–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        
        Returns:
            –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (input + expected output)
        """
        # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: 1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ/–∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ
        message_tokens = len(message) // 4
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        history_tokens = 0
        if conversation_history:
            for msg in conversation_history[-10:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
                history_tokens += len(msg.get("content", "")) // 4
        
        # –û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç (–æ–±—ã—á–Ω–æ –±–æ–ª—å—à–µ —á–µ–º –∑–∞–ø—Ä–æ—Å)
        expected_output_tokens = message_tokens * 2
        
        total = message_tokens + history_tokens + expected_output_tokens
        
        # –û–∫—Ä—É–≥–ª—è–µ–º –≤–≤–µ—Ä—Ö —Å –∑–∞–ø–∞—Å–æ–º
        return int(total * 1.2)
    
    def select_optimal_model(
        self,
        user_tier: SubscriptionTier,
        message: str,
        conversation_history: List[Dict] = None,
        user_stats: Dict = None,
        preferred_model: Optional[str] = None
    ) -> Dict:
        """
        –í—ã–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á–∏
        
        Args:
            user_tier: –¢–∞—Ä–∏—Ñ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
            user_stats: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è {total_tokens_used, premium_tokens_used}
            preferred_model: –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º–∞—è –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞)
        
        Returns:
            {
                "model_id": str,
                "reason": str,
                "estimated_cost_rub": float,
                "task_type": str,
                "alternative_models": List[str]
            }
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
        task_type = self.detect_task_type(message)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
        estimated_tokens = self.estimate_tokens(message, conversation_history)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∞–≤–∏–ª–∞ —Ç–∞—Ä–∏—Ñ–∞
        rules = MODEL_ACCESS_RULES[user_tier]
        
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∫–∞–∑–∞–ª –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ –∏ –æ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω–æ
        if preferred_model:
            model_category = get_model_category(preferred_model)
            if model_category not in rules["blocked_categories"]:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –ø—Ä–µ–º–∏—É–º –º–æ–¥–µ–ª–µ–π
                if self._check_premium_limit(user_tier, model_category, user_stats, estimated_tokens):
                    return self._build_response(preferred_model, task_type, estimated_tokens, "user_preference")
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∞—Ä–∏—Ñ–∞ –∏ –∑–∞–¥–∞—á–∏
        selected_model = self._auto_select_model(user_tier, task_type, user_stats, estimated_tokens)
        
        return self._build_response(selected_model, task_type, estimated_tokens, "auto_selected")
    
    def _check_premium_limit(
        self,
        user_tier: SubscriptionTier,
        model_category: ModelCategory,
        user_stats: Optional[Dict],
        estimated_tokens: int
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–∏–º–∏—Ç –ø—Ä–µ–º–∏—É–º –º–æ–¥–µ–ª–µ–π"""
        if model_category not in [ModelCategory.PREMIUM, ModelCategory.ULTRA]:
            return True  # –ù–µ –ø—Ä–µ–º–∏—É–º - –≤—Å–µ–≥–¥–∞ OK
        
        if not user_stats:
            return True  # –ù–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ - —Ä–∞–∑—Ä–µ—à–∞–µ–º
        
        from subscription_plans_optimized import SUBSCRIPTION_PLANS
        
        rules = MODEL_ACCESS_RULES[user_tier]
        plan = SUBSCRIPTION_PLANS[user_tier]
        
        premium_limit = int(plan["tokens_limit"] * rules["premium_limit_percent"] / 100)
        premium_used = user_stats.get("premium_tokens_used", 0)
        
        return (premium_used + estimated_tokens) <= premium_limit
    
    def _auto_select_model(
        self,
        user_tier: SubscriptionTier,
        task_type: str,
        user_stats: Optional[Dict],
        estimated_tokens: int
    ) -> str:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å"""
        
        # MINI —Ç–∞—Ä–∏—Ñ - —Ç–æ–ª—å–∫–æ –¥–µ—à–µ–≤—ã–µ –º–æ–¥–µ–ª–∏
        if user_tier == SubscriptionTier.MINI:
            if task_type == "coding":
                return "openai/gpt-4o-mini"
            return "google/gemini-2.0-flash-001"
        
        # STARTER - –¥–µ—à–µ–≤—ã–µ + –Ω–µ–º–Ω–æ–≥–æ GPT-4o
        if user_tier == SubscriptionTier.STARTER:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç GPT-4o (10%)
            can_use_premium = self._check_premium_limit(
                user_tier, ModelCategory.MEDIUM, user_stats, estimated_tokens
            )
            
            if can_use_premium and task_type in ["coding", "analysis"]:
                return "openai/gpt-4o"
            
            if task_type == "coding":
                return "openai/gpt-4o-mini"
            
            return "google/gemini-2.5-flash"
        
        # PRO - –≤–∫–ª—é—á–∞–µ–º –ø—Ä–µ–º–∏—É–º –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á
        if user_tier == SubscriptionTier.PRO:
            can_use_premium = self._check_premium_limit(
                user_tier, ModelCategory.PREMIUM, user_stats, estimated_tokens
            )
            
            if can_use_premium:
                if task_type == "creative":
                    return "anthropic/claude-sonnet-4"
                if task_type == "analysis":
                    return "anthropic/claude-sonnet-4"
                if task_type == "coding":
                    return "openai/gpt-4o"
            
            # –ï—Å–ª–∏ –ª–∏–º–∏—Ç –ø—Ä–µ–º–∏—É–º –∏—Å—á–µ—Ä–ø–∞–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—à–µ–≤—ã–µ
            if task_type == "coding":
                return "openai/gpt-4o"
            return "google/gemini-2.5-flash"
        
        # BUSINESS - –ª—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
        if task_type == "creative":
            return "anthropic/claude-sonnet-4.5"
        if task_type == "analysis":
            return "anthropic/claude-sonnet-4.5"
        if task_type == "coding":
            return "openai/gpt-4o"
        
        return "openai/gpt-4o"
    
    def _build_response(
        self,
        model_id: str,
        task_type: str,
        estimated_tokens: int,
        selection_reason: str
    ) -> Dict:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –æ—Ç–≤–µ—Ç —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é"""
        cost_per_million = get_model_cost(model_id)
        estimated_cost = (estimated_tokens / 1_000_000) * cost_per_million
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏
        alternatives = self._get_alternatives(model_id, task_type)
        
        return {
            "model_id": model_id,
            "reason": selection_reason,
            "estimated_cost_rub": round(estimated_cost, 2),
            "estimated_tokens": estimated_tokens,
            "task_type": task_type,
            "alternative_models": alternatives,
            "model_category": get_model_category(model_id).value,
        }
    
    def _get_alternatives(self, selected_model: str, task_type: str) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        category = get_model_category(selected_model)
        
        alternatives = []
        
        # –í—Å–µ–≥–¥–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —Å–∞–º—ã–µ –¥–µ—à–µ–≤—ã–µ
        if selected_model != "google/gemini-2.0-flash-001":
            alternatives.append("google/gemini-2.0-flash-001")
        
        if selected_model != "openai/gpt-4o-mini" and task_type == "coding":
            alternatives.append("openai/gpt-4o-mini")
        
        # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –¥–µ—à–µ–≤–∞—è, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø—Ä–µ–º–∏—É–º
        if category == ModelCategory.CHEAP:
            if task_type in ["creative", "analysis"]:
                alternatives.append("anthropic/claude-sonnet-4")
            else:
                alternatives.append("openai/gpt-4o")
        
        return alternatives[:3]  # –ú–∞–∫—Å–∏–º—É–º 3 –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
    
    def explain_model_choice(self, model_response: Dict) -> str:
        """
        –û–±—ä—è—Å–Ω–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω–∞ —ç—Ç–∞ –º–æ–¥–µ–ª—å
        
        Returns:
            –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        """
        model_id = model_response["model_id"]
        task_type = model_response["task_type"]
        cost = model_response["estimated_cost_rub"]
        
        # –ù–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        model_names = {
            "google/gemini-2.0-flash-001": "Gemini Flash (–±—ã—Å—Ç—Ä–∞—è)",
            "google/gemini-2.5-flash": "Gemini 2.5 Flash",
            "openai/gpt-4o-mini": "GPT-4o Mini",
            "openai/gpt-4o": "GPT-4o",
            "anthropic/claude-sonnet-4": "Claude Sonnet 4",
            "anthropic/claude-sonnet-4.5": "Claude Sonnet 4.5",
        }
        
        task_names = {
            "coding": "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è",
            "creative": "—Ç–≤–æ—Ä—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á",
            "analysis": "–∞–Ω–∞–ª–∏–∑–∞",
            "translation": "–ø–µ—Ä–µ–≤–æ–¥–∞",
            "math": "–º–∞—Ç–µ–º–∞—Ç–∏–∫–∏",
            "general": "–æ–±—â–∏—Ö –∑–∞–¥–∞—á",
        }
        
        model_name = model_names.get(model_id, model_id)
        task_name = task_names.get(task_type, "—ç—Ç–æ–π –∑–∞–¥–∞—á–∏")
        
        explanation = f"üí° –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å {model_name} –¥–ª—è {task_name}"
        
        if cost < 0.5:
            explanation += " (—ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)"
        elif cost > 5:
            explanation += " (–ø—Ä–µ–º–∏—É–º –∫–∞—á–µ—Å—Ç–≤–æ)"
        
        return explanation

# ============================================
# –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø
# ============================================

"""
from smart_model_router import SmartModelRouter

router = SmartModelRouter()

# –í –≤–∞—à–µ–º chat endpoint:
@app.post("/chat")
async def chat(request: ChatRequest, user = Depends(get_current_user)):
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    stats = await get_user_stats(user.id)
    
    # –£–º–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_selection = router.select_optimal_model(
        user_tier=user.subscription_tier,
        message=request.message,
        conversation_history=request.history,
        user_stats=stats,
        preferred_model=request.model_id  # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª
    )
    
    # –û–±—ä—è—Å–Ω—è–µ–º –≤—ã–±–æ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    explanation = router.explain_model_choice(model_selection)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    response = await send_to_openrouter(
        model_id=model_selection["model_id"],
        messages=request.messages
    )
    
    return {
        "response": response,
        "model_used": model_selection["model_id"],
        "explanation": explanation,
        "estimated_cost": model_selection["estimated_cost_rub"],
    }
"""
